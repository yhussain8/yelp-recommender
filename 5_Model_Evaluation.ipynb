{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "The purpose of this workbook will be to evaluate the performance of the user-item filtering and item-item filtering systems that we developed in the previous workbooks.\n",
    "\n",
    "First, I will copy over the final version of the formulas that I developed in the previous two workbooks.\n",
    "\n",
    "I will then use the `sklearn` package's `train_test_split` function to select a random sample of users for which I will use as my test set.\n",
    "\n",
    "Using this set of test users, I will attempt to generate a rating for each user using a combination of the two filtering systems I developed. I will use the Root Mean Squared Error (RMSE) formula to evaluate the performance of my each filtering system. Note that a lower RSME value indicates a better performing model.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries as needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import matplotlib.pyplot as plt ~ not utilized in this workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ratings_matrix data-frame as created in a previous workbook\n",
    "ratings_matrix = pd.read_pickle('data/user/ratings_matrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the review table as created in the data processing workbook\n",
    "review = pd.read_pickle('data/user/review.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the list of unique users and businesses numbers used to build ratings matrix and their corresponding original user_id and business_id values\n",
    "unique_user = pd.read_pickle('data/user/unique_user.pkl')\n",
    "unique_business = pd.read_pickle('data/user/unique_business.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6548</th>\n",
       "      <th>6549</th>\n",
       "      <th>6550</th>\n",
       "      <th>6551</th>\n",
       "      <th>6552</th>\n",
       "      <th>6553</th>\n",
       "      <th>6554</th>\n",
       "      <th>6555</th>\n",
       "      <th>6556</th>\n",
       "      <th>6557</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96527</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96528</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96529</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96530</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96531</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96532 rows × 6558 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...  6548  \\\n",
       "0       4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "1       5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "2       1.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "3       4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "4       1.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "96527   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "96528   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "96529   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "96530   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "96531   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "\n",
       "       6549  6550  6551  6552  6553  6554  6555  6556  6557  \n",
       "0       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "96527   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "96528   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "96529   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   5.0  \n",
       "96530   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "96531   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[96532 rows x 6558 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the ratings matrix\n",
    "ratings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function with the user_id value of any two users as the two parameters for the function\n",
    "def find_user_similarity(userA, userB, ratings_matrix):\n",
    "    # Create a True/False list of businesses that were given a rating for each of the two users\n",
    "    businesses_rated_by_userA = ~ratings_matrix.loc[userA, :].isna()\n",
    "    businesses_rated_by_userB = ~ratings_matrix.loc[userB, :].isna()\n",
    "\n",
    "    # Consolidate the two boolean lists into a single one which represents only those businesses rated by both users\n",
    "    businesses_rated_by_both_users = businesses_rated_by_userA & businesses_rated_by_userB\n",
    "\n",
    "    # Capture the rating values of both users for those businesses that were rated by both users\n",
    "    # Also transform these values into a format suitable for the cosine_similarity function\n",
    "    ratings_of_userA = ratings_matrix.loc[userA, businesses_rated_by_both_users].values.reshape(1, -1)\n",
    "    ratings_of_userB = ratings_matrix.loc[userB, businesses_rated_by_both_users].values.reshape(1, -1)\n",
    "\n",
    "    # Capture the similaritiy between the two users by comparing their ratings for the set of businesses that they have both provided a rating for\n",
    "    similarity = cosine_similarity(ratings_of_userA, ratings_of_userB)[0][0]\n",
    "\n",
    "    # Return the consine similarity value as the output of this function\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the user-item rating prediction based on cosine similarity, with the following two parameters:\n",
    "# target_business = business_id value for business for whom rating is being predicted for\n",
    "# target_user = user_id value for the user for whom rating is being predicted for\n",
    "def user_item_rating_prediction(target_user, target_business, ratings_matrix):\n",
    "\n",
    "    # Create empty lists to store the:\n",
    "    # 1. Similarities with other users to our target user\n",
    "    similarities_to_target_user = []\n",
    "    # 2. Existing ratings provided to our target business\n",
    "    ratings_given_to_target_business = []\n",
    "\n",
    "    # Create a list of all users that have provided a rating for the target business\n",
    "    list_of_users_rating_target_business = list(ratings_matrix[~ratings_matrix.iloc[:, target_business].isna()].index)\n",
    "\n",
    "    # Loop over every user in our target ratings matrix\n",
    "    # We can refer to each user as the 'other_user' since we know that our target user did not provide a rating for our target business and hence is not in this smaller data frame\n",
    "    for other_user in list_of_users_rating_target_business:\n",
    "        # To compensate for the value error that may occur when the two users we are comparing have 0 businesses that they have both rated together\n",
    "        try:\n",
    "            # Capture the cosine similarity between our target user and the current user from the list of user we are looping over\n",
    "            similarity = find_user_similarity(target_user, other_user, ratings_matrix)\n",
    "            # Capture this similarity value to our list of similarity values\n",
    "            similarities_to_target_user.append(similarity)\n",
    "            # Capture the rating value of the current 'other_user' into our list of ratings given to our target businesses\n",
    "            ratings_given_to_target_business.append(ratings_matrix.loc[other_user, target_business])\n",
    "        # If a value error is generated, we simply pass over to the next loop\n",
    "        # Since we will not be appending no values to neither our list of similarities and list of ratings, we will not be impacting our final calculation\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Use the cosine similarity value to calculate the weighted average of all ratings (for those users that have at least 1 business that they have rated together)\n",
    "    return np.dot(ratings_given_to_target_business, similarities_to_target_user)/np.sum(similarities_to_target_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function with the business_id value of any two businesses as the two parameters for the function\n",
    "def find_business_similarity(businessA, businessB, ratings_matrix):\n",
    "    \n",
    "    # Create a True/False list of users that gave a rating for each of the two businesses\n",
    "    users_who_rated_businessA = ~ratings_matrix.loc[:, businessA].isna()\n",
    "    users_who_rated_businessB = ~ratings_matrix.loc[:, businessB].isna()\n",
    "    \n",
    "    # Consolidate the two boolean lists into a single one which represents only those users that rated both businesses\n",
    "    users_who_rated_both_businesses = users_who_rated_businessA & users_who_rated_businessB\n",
    "    \n",
    "    # Capture the rating values of both businesses for those users that rated both businesses\n",
    "    # Also transform these values into a format suitable for the cosine_similarity function\n",
    "    ratings_of_businessA = ratings_matrix.loc[users_who_rated_both_businesses, businessA].values.reshape(1, -1)\n",
    "    ratings_of_businessB = ratings_matrix.loc[users_who_rated_both_businesses, businessB].values.reshape(1, -1)\n",
    "    \n",
    "    # Capture the similaritiy between the two businesses by comparing their ratings for the set of users that both provided a rating for them\n",
    "    similarity = cosine_similarity(ratings_of_businessA, ratings_of_businessB)[0][0]\n",
    "    \n",
    "    # Return the consine similarity value as the output of this function\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the user-item rating prediction based on cosine similarity, with the following two parameters:\n",
    "# target_business = business_id value for business for whom rating is being predicted for\n",
    "# target_user = user_id value for the user for whom rating is being predicted for\n",
    "def item_item_rating_prediction(target_user, target_business, ratings_matrix):\n",
    "   \n",
    "    # Create empty lists to store the:\n",
    "    # 1. Similarities with other users to our target user\n",
    "    similarities_to_target_business = []\n",
    "    # 2. Existing ratings provided to our target business\n",
    "    ratings_given_by_target_user = []\n",
    "    \n",
    "    # Create a list of all users that have provided a rating for the target business\n",
    "    list_of_businesses_rated_by_target_user = list(ratings_matrix.loc[:, ~ratings_matrix.iloc[target_user, :].isna()].columns)\n",
    "    \n",
    "    # Loop over every user in our target ratings matrix\n",
    "    # We can refer to each user as the 'other_user' since we know that our target user did not provide a rating for our target business and hence is not in this smaller data frame\n",
    "    for other_business in list_of_businesses_rated_by_target_user:\n",
    "        # To compensate for the value error that may occur when the two users we are comparing have 0 businesses that they have both rated together\n",
    "        try:\n",
    "            # Capture the cosine similarity between our target user and the current user from the list of user we are looping over\n",
    "            similarity = find_business_similarity(target_business, other_business, ratings_matrix)\n",
    "            # Capture this similarity value to our list of similarity values\n",
    "            similarities_to_target_business.append(similarity)\n",
    "            # Capture the rating value of the current 'other_user' into our list of ratings given to our target businesses\n",
    "            ratings_given_by_target_user.append(ratings_matrix.loc[target_user, other_business])\n",
    "        # If a value error is generated, we simply pass over to the next loop\n",
    "        # Since we will not be appending no values to neither our list of similarities and list of ratings, we will not be impacting our final calculation\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Use the cosine similarity value to calculate the weighted average of all ratings (for those users that have at least 1 business that they have rated together)\n",
    "    return np.dot(ratings_given_by_target_user, similarities_to_target_business)/np.sum(similarities_to_target_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7220670351652867"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm formuala is working as intended (as tested in previous notebook)\n",
    "user_item_rating_prediction(0, 1, ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7917695651231935"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm formuala is working as intended (as tested in previous notebook)\n",
    "item_item_rating_prediction(0, 1, ratings_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Create Train-Test Split of the Ratings Matrix to Evaluate the Peformance of the Two Different Filtering Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the ratings matrix into a train test split \n",
    "train_df, test_df = train_test_split(ratings_matrix, test_size = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96512, 6558)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the shape of the training split\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 6558)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the shape of the testing split\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the specific users included in the test set\n",
    "test_users = pd.Series(list(test_df.index), name = 'user_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the review df such that we can manipulate it for our testing and evaluation methods\n",
    "review2 = review.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the list of unique users and unique business numbers used for ratings matrix back into the review table\n",
    "review2 = pd.merge(review2, unique_user, how = 'left')\n",
    "review2 = pd.merge(review2, unique_business, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the df by the date values, such that the most recent reviews are at the top\n",
    "# This is so that we keep the most recent reviews when deleting duplicates for each user-business combination\n",
    "review2 = review2.sort_values('date', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378098, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review size of df before dropping duplicates\n",
    "review2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates for each unique user-business combination\n",
    "review2 = review2.drop_duplicates(subset = ['user_num', 'business_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367390, 11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review size of df after dropping duplicates\n",
    "review2.shape\n",
    "\n",
    "# Note we now have exactly the same number of records that we used to originally create our ratings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all unncessary columns except the 3 we will be using for our testing and evaluation purposes\n",
    "review2 = review2[['user_num', 'business_num', 'stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep those records in our df that match with the set of users included in our testing set\n",
    "review2 = pd.merge(review2, test_users, on = 'user_num', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review shape of df after dropping all records whose users do not tie back to our testing set\n",
    "review2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to check that we have the right match of user-business star ratings to that of our ratings matrix\n",
    "review2.insert(3, 'check', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in the records from the ratings matrix for each unique user-business combo\n",
    "for record in review2.index:\n",
    "    review2.loc[record, ['check']] = ratings_matrix.loc[review2.loc[record, ['user_num'][0]], review2.loc[record, ['business_num'][0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate that there is no discrenpancies between the values we have chosen for our reviews2 df and our ratings matrix\n",
    "(review2['stars'] - review2['check']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'check' column since it has now served its purpose\n",
    "review2 = review2.drop(columns = {'check'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns inside the review2 df where each value is a nan value to be filled in by the respective user-item and item-item rating predictions\n",
    "review2.insert(3, 'user-item', np.nan)\n",
    "review2.insert(4, 'item-item', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.36 s, sys: 411 ms, total: 9.77 s\n",
      "Wall time: 9.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Print the cell execution time (for my laptop this was approx. 30 sec. for a test_size of 0.0002)\n",
    "\n",
    "# Loop over every record in the review df\n",
    "for record in review2.index:\n",
    "    # Capture the user num and business num values for each record being loop over\n",
    "    user_num = review2.loc[record, ['user_num'][0]]\n",
    "    business_num = review2.loc[record, ['business_num'][0]]\n",
    "    \n",
    "    # Use the user num and business num to generate both the user-item and item-item rating predictions\n",
    "    review2.loc[record, ['user-item']] = round(user_item_rating_prediction(user_num, business_num, ratings_matrix),2)\n",
    "    review2.loc[record, ['item-item']] = round(item_item_rating_prediction(user_num, business_num, ratings_matrix),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Now that we have made a prediction against each ratings value from our set of test data, we will evaluate the predictions by calculating the Root Mean Squared Error (RMSE) for each set of user-item, item-item, and weighted-average hybrid predictions against the original star rating.\n",
    "\n",
    "Formula for RMSE taken from link below:\n",
    "\n",
    "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the Root Mean Squared Error between the original rating and the predicted rating\n",
    "# The two parameters will be a list or Series of predicted ratings vs the original target ratings\n",
    "def rmse(predictions, targets):\n",
    "    # Take the sum of squared differences between the predicted and target ratings, calculate its mean, and then determine its square root\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.434158379123539"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the RMSE value of the user-item predictions\n",
    "rmse(review2['user-item'], review2['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9370699013414101"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the RMSE value of the item-item predictions\n",
    "rmse(review2['item-item'], review2['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a series of 9 columns which each combine the user-item and item-item predictions using a weighted-average\n",
    "# Each column represents a different weight ranging from using 10% of the user-item rating and 90% of the item-item rating (hybrid10)...\n",
    "# ...to using 90% of the user-item rating and 10% of the item-item rating (hybrid90)\n",
    "review2.insert(5, 'hybrid10', (review2['user-item']*0.1 + review2['item-item']*.9))\n",
    "review2.insert(6, 'hybrid20', (review2['user-item']*0.2 + review2['item-item']*.8))\n",
    "review2.insert(7, 'hybrid30', (review2['user-item']*0.3 + review2['item-item']*.7))\n",
    "review2.insert(8, 'hybrid40', (review2['user-item']*0.4 + review2['item-item']*.6))\n",
    "review2.insert(9, 'hybrid50', (review2['user-item']*0.5 + review2['item-item']*.5))\n",
    "review2.insert(10, 'hybrid60', (review2['user-item']*0.6 + review2['item-item']*.4))\n",
    "review2.insert(11, 'hybrid70', (review2['user-item']*0.7 + review2['item-item']*.3))\n",
    "review2.insert(12, 'hybrid80', (review2['user-item']*0.8 + review2['item-item']*.2))\n",
    "review2.insert(13, 'hybrid90', (review2['user-item']*0.9 + review2['item-item']*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_num</th>\n",
       "      <th>business_num</th>\n",
       "      <th>stars</th>\n",
       "      <th>user-item</th>\n",
       "      <th>item-item</th>\n",
       "      <th>hybrid10</th>\n",
       "      <th>hybrid20</th>\n",
       "      <th>hybrid30</th>\n",
       "      <th>hybrid40</th>\n",
       "      <th>hybrid50</th>\n",
       "      <th>hybrid60</th>\n",
       "      <th>hybrid70</th>\n",
       "      <th>hybrid80</th>\n",
       "      <th>hybrid90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53732</td>\n",
       "      <td>2549</td>\n",
       "      <td>5</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.950</td>\n",
       "      <td>4.900</td>\n",
       "      <td>4.850</td>\n",
       "      <td>4.800</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.700</td>\n",
       "      <td>4.650</td>\n",
       "      <td>4.600</td>\n",
       "      <td>4.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31640</td>\n",
       "      <td>5272</td>\n",
       "      <td>3</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.502</td>\n",
       "      <td>3.504</td>\n",
       "      <td>3.506</td>\n",
       "      <td>3.508</td>\n",
       "      <td>3.51</td>\n",
       "      <td>3.512</td>\n",
       "      <td>3.514</td>\n",
       "      <td>3.516</td>\n",
       "      <td>3.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31640</td>\n",
       "      <td>809</td>\n",
       "      <td>4</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.576</td>\n",
       "      <td>3.652</td>\n",
       "      <td>3.728</td>\n",
       "      <td>3.804</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.956</td>\n",
       "      <td>4.032</td>\n",
       "      <td>4.108</td>\n",
       "      <td>4.184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_num  business_num  stars  user-item  item-item  hybrid10  hybrid20  \\\n",
       "0     53732          2549      5       4.50        5.0     4.950     4.900   \n",
       "1     31640          5272      3       3.52        3.5     3.502     3.504   \n",
       "2     31640           809      4       4.26        3.5     3.576     3.652   \n",
       "\n",
       "   hybrid30  hybrid40  hybrid50  hybrid60  hybrid70  hybrid80  hybrid90  \n",
       "0     4.850     4.800      4.75     4.700     4.650     4.600     4.550  \n",
       "1     3.506     3.508      3.51     3.512     3.514     3.516     3.518  \n",
       "2     3.728     3.804      3.88     3.956     4.032     4.108     4.184  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick overview of the final version of the reviews2 df\n",
    "review2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-item: 0.9370699013414101\n",
      "hybrid10: 0.935326612363228\n",
      "hybrid20: 0.9478874757410117\n",
      "hybrid30: 0.9741993556841352\n",
      "hybrid40: 1.0131915049194922\n",
      "hybrid50: 1.0634700699801523\n",
      "hybrid60: 1.123520839558874\n",
      "hybrid70: 1.1918676466703368\n",
      "hybrid80: 1.2671688208414933\n",
      "hybrid90: 1.348259647442983\n",
      "user-item: 1.434158379123539\n"
     ]
    }
   ],
   "source": [
    "# Print the range of RMSE values for each of the rating prediction columns\n",
    "# Ranging from using 100% of the item-item ratings to 100% of the user-item ratings\n",
    "print('item-item:', rmse(review2['item-item'], review2['stars']))\n",
    "print('hybrid10:', rmse(review2['hybrid10'], review2['stars']))\n",
    "print('hybrid20:', rmse(review2['hybrid20'], review2['stars']))\n",
    "print('hybrid30:', rmse(review2['hybrid30'], review2['stars']))\n",
    "print('hybrid40:', rmse(review2['hybrid40'], review2['stars']))\n",
    "print('hybrid50:', rmse(review2['hybrid50'], review2['stars']))\n",
    "print('hybrid60:', rmse(review2['hybrid60'], review2['stars']))\n",
    "print('hybrid70:', rmse(review2['hybrid70'], review2['stars']))\n",
    "print('hybrid80:', rmse(review2['hybrid80'], review2['stars']))\n",
    "print('hybrid90:', rmse(review2['hybrid90'], review2['stars']))\n",
    "print('user-item:', rmse(review2['user-item'], review2['stars']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Here we see that using a pure item-item based approach is much better than using a pure user-item based filtering system.\n",
    "\n",
    "By using a hybrid approach which takes the weighted average of the two rating predictions, we are able to further reduce our Root Squared Mean Error (RSME).\n",
    "\n",
    "The best approach using the last random test sample that I ran this workbook for, indicated that taking a weighted average of 20% user-item rating and 80% item-item rating yeilded the best results.  Having ran this workbook multiple times, I noticed that the best hybrid approach ranges from using 20% to 40% of the user-item rating and 80% to 60% of the item-item rating.\n",
    "\n",
    "However, having ran this workbook multiple times, I consistently noticed that the lowest RSME was from the 'hybrid20' column.  Therefore, my final collaborative recommender system will use a weighted average of 20% against the user-item rating and 80% against the item-item rating."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surprise-env-kernel",
   "language": "python",
   "name": "surprise-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
